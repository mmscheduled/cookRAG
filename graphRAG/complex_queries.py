"""
å¤æ‚å…³ç³»æŸ¥è¯¢åŠŸèƒ½
å®ç°é«˜çº§çš„å›¾æŸ¥è¯¢å’Œå…³ç³»åˆ†æåŠŸèƒ½
"""

import re
from typing import List, Dict, Set, Tuple, Optional, Any
from collections import defaultdict, Counter
from dataclasses import dataclass

from graph_models import RecipeGraph, GraphNode, NodeType, EdgeType
from graph_storage import GraphQueryEngine


@dataclass
class QueryResult:
    """æŸ¥è¯¢ç»“æœ"""
    query_type: str
    results: List[Any]
    metadata: Dict[str, Any] = None
    
    def __post_init__(self):
        if self.metadata is None:
            self.metadata = {}


class ComplexQueryProcessor:
    """å¤æ‚æŸ¥è¯¢å¤„ç†å™¨"""
    
    def __init__(self, query_engine: GraphQueryEngine, recommendation_engine=None, llm_integration=None):
        self.query_engine = query_engine
        self.graph = query_engine.graph
        self.recommendation_engine = recommendation_engine
        self.llm_integration = llm_integration
    
    def process_natural_language_query(self, query: str) -> QueryResult:
        """å¤„ç†è‡ªç„¶è¯­è¨€æŸ¥è¯¢"""
        query_lower = query.lower()
        
        # æŸ¥è¯¢ç±»å‹è¯†åˆ«ï¼ˆæŒ‰ä¼˜å…ˆçº§æ’åºï¼Œæ›´å…·ä½“çš„æŸ¥è¯¢ç±»å‹ä¼˜å…ˆï¼‰
        if any(keyword in query_lower for keyword in ['å‘ç°', 'çƒ­é—¨', 'æµè¡Œ', 'è¶‹åŠ¿']):
            return self._process_discovery_query(query)
        elif any(keyword in query_lower for keyword in ['ç›¸ä¼¼', 'ç±»ä¼¼', 'åƒ']):
            return self._process_similarity_query(query)
        elif any(keyword in query_lower for keyword in ['æ¨è', 'å»ºè®®', 'å¯ä»¥']):
            return self._process_recommendation_query(query)
        elif any(keyword in query_lower for keyword in ['æ›¿ä»£', 'æ›¿æ¢', 'ä»£æ›¿']):
            return self._process_substitution_query(query)
        elif any(keyword in query_lower for keyword in ['æ­é…', 'é…', 'å’Œ', 'ä¸€èµ·']):
            return self._process_pairing_query(query)
        elif any(keyword in query_lower for keyword in ['æ–¹æ³•', 'åšæ³•', 'çƒ¹é¥ª']):
            return self._process_cooking_method_query(query)
        elif any(keyword in query_lower for keyword in ['é£Ÿæ', 'åŸæ–™', 'ææ–™']):
            return self._process_ingredient_query(query)
        elif any(keyword in query_lower for keyword in ['åˆ†æ', 'äº†è§£', 'ä»‹ç»', 'è¯´æ˜']):
            return self._process_analysis_query(query)
        else:
            return self._process_general_query(query)
    
    def _process_pairing_query(self, query: str) -> QueryResult:
        """å¤„ç†æ­é…æŸ¥è¯¢"""
        # æå–é£Ÿæåç§°
        ingredients = self._extract_ingredients_from_query(query)
        
        if not ingredients:
            return QueryResult("pairing", [], {"error": "æœªæ‰¾åˆ°é£Ÿæä¿¡æ¯"})
        
        # æŸ¥æ‰¾æ­é…å…³ç³»
        all_pairs = []
        for ingredient in ingredients:
            pairs = self.query_engine.find_ingredient_pairs(ingredient)
            all_pairs.extend(pairs)
        
        # å»é‡å¹¶æ’åº
        pair_dict = {}
        for ingredient, count in all_pairs:
            if ingredient.name not in pair_dict:
                pair_dict[ingredient.name] = (ingredient, count)
            else:
                # å–æ›´é«˜çš„é¢‘ç‡
                if count > pair_dict[ingredient.name][1]:
                    pair_dict[ingredient.name] = (ingredient, count)
        
        results = list(pair_dict.values())
        results.sort(key=lambda x: x[1], reverse=True)
        
        return QueryResult("pairing", results, {
            "query_ingredients": ingredients,
            "total_pairs": len(results)
        })
    
    def _process_recommendation_query(self, query: str) -> QueryResult:
        """å¤„ç†æ¨èæŸ¥è¯¢"""
        # æå–é£Ÿææˆ–èœå“ä¿¡æ¯
        ingredients = self._extract_ingredients_from_query(query)
        dishes = self._extract_dishes_from_query(query)
        
        recommendations = []
        
        if ingredients:
            # åŸºäºé£Ÿææ¨èèœå“
            dish_recommendations = self.query_engine.find_dishes_by_ingredients(ingredients)
            recommendations.extend(dish_recommendations)
        
        if dishes:
            # åŸºäºèœå“æ¨èç›¸ä¼¼èœå“
            for dish in dishes:
                similar_dishes = self.query_engine.find_similar_dishes(dish)
                recommendations.extend(similar_dishes)
        
        # å»é‡å¹¶æ’åº
        unique_recommendations = {}
        for item, score in recommendations:
            if item.name not in unique_recommendations:
                unique_recommendations[item.name] = (item, score)
            else:
                if score > unique_recommendations[item.name][1]:
                    unique_recommendations[item.name] = (item, score)
        
        results = list(unique_recommendations.values())
        results.sort(key=lambda x: x[1], reverse=True)
        
        return QueryResult("recommendation", results, {
            "query_ingredients": ingredients,
            "query_dishes": dishes,
            "total_recommendations": len(results)
        })
    
    def _process_substitution_query(self, query: str) -> QueryResult:
        """å¤„ç†æ›¿ä»£æŸ¥è¯¢"""
        ingredients = self._extract_ingredients_from_query(query)
        
        if not ingredients:
            return QueryResult("substitution", [], {"error": "æœªæ‰¾åˆ°é£Ÿæä¿¡æ¯"})
        
        substitutions = []
        for ingredient in ingredients:
            suggestions = self.query_engine.get_ingredient_substitution_suggestions(ingredient)
            substitutions.extend(suggestions)
        
        # å»é‡å¹¶æ’åº
        sub_dict = {}
        for ingredient, score in substitutions:
            if ingredient.name not in sub_dict:
                sub_dict[ingredient.name] = (ingredient, score)
            else:
                if score > sub_dict[ingredient.name][1]:
                    sub_dict[ingredient.name] = (ingredient, score)
        
        results = list(sub_dict.values())
        results.sort(key=lambda x: x[1], reverse=True)
        
        return QueryResult("substitution", results, {
            "query_ingredients": ingredients,
            "total_substitutions": len(results)
        })
    
    def _process_similarity_query(self, query: str) -> QueryResult:
        """å¤„ç†ç›¸ä¼¼æ€§æŸ¥è¯¢"""
        dishes = self._extract_dishes_from_query(query)
        
        if not dishes:
            return QueryResult("similarity", [], {"error": "æœªæ‰¾åˆ°èœå“ä¿¡æ¯"})
        
        similar_dishes = []
        for dish in dishes:
            similar = self.query_engine.find_similar_dishes(dish)
            similar_dishes.extend(similar)
        
        # å»é‡å¹¶æ’åº
        sim_dict = {}
        for dish, score in similar_dishes:
            if dish.name not in sim_dict:
                sim_dict[dish.name] = (dish, score)
            else:
                if score > sim_dict[dish.name][1]:
                    sim_dict[dish.name] = (dish, score)
        
        results = list(sim_dict.values())
        results.sort(key=lambda x: x[1], reverse=True)
        
        return QueryResult("similarity", results, {
            "query_dishes": dishes,
            "total_similar": len(results)
        })
    
    def _process_cooking_method_query(self, query: str) -> QueryResult:
        """å¤„ç†çƒ¹é¥ªæ–¹æ³•æŸ¥è¯¢"""
        ingredients = self._extract_ingredients_from_query(query)
        methods = self._extract_cooking_methods_from_query(query)
        
        results = []
        
        if ingredients:
            # æŸ¥æ‰¾é£Ÿæçš„å¸¸ç”¨çƒ¹é¥ªæ–¹æ³•
            for ingredient in ingredients:
                methods_for_ingredient = self.query_engine.find_cooking_methods_for_ingredient(ingredient)
                results.extend(methods_for_ingredient)
        
        if methods:
            # æŸ¥æ‰¾çƒ¹é¥ªæ–¹æ³•çš„å¸¸ç”¨é£Ÿæ
            for method in methods:
                ingredients_for_method = self.query_engine.find_ingredients_by_cooking_method(method)
                results.extend(ingredients_for_method)
        
        # å»é‡å¹¶æ’åº
        result_dict = {}
        for item, count in results:
            if item.name not in result_dict:
                result_dict[item.name] = (item, count)
            else:
                if count > result_dict[item.name][1]:
                    result_dict[item.name] = (item, count)
        
        final_results = list(result_dict.values())
        final_results.sort(key=lambda x: x[1], reverse=True)
        
        return QueryResult("cooking_method", final_results, {
            "query_ingredients": ingredients,
            "query_methods": methods,
            "total_results": len(final_results)
        })
    
    def _process_ingredient_query(self, query: str) -> QueryResult:
        """å¤„ç†é£ŸææŸ¥è¯¢"""
        dishes = self._extract_dishes_from_query(query)
        
        if not dishes:
            return QueryResult("ingredient", [], {"error": "æœªæ‰¾åˆ°èœå“ä¿¡æ¯"})
        
        all_ingredients = []
        for dish in dishes:
            # æŸ¥æ‰¾èœå“èŠ‚ç‚¹
            dish_nodes = self.query_engine.search_nodes(dish, NodeType.DISH)
            for dish_node in dish_nodes:
                ingredients = self.graph.get_neighbors(dish_node.id, EdgeType.CONTAINS)
                all_ingredients.extend(ingredients)
        
        # ç»Ÿè®¡é£Ÿæé¢‘ç‡
        ingredient_counts = Counter(ingredient.name for ingredient in all_ingredients)
        
        # è½¬æ¢ä¸ºç»“æœæ ¼å¼
        results = []
        for ingredient_name, count in ingredient_counts.most_common():
            ingredient_node = self.query_engine.search_nodes(ingredient_name, NodeType.INGREDIENT)
            if ingredient_node:
                results.append((ingredient_node[0], count))
        
        return QueryResult("ingredient", results, {
            "query_dishes": dishes,
            "total_ingredients": len(results)
        })
    
    def _process_discovery_query(self, query: str) -> QueryResult:
        """å¤„ç†å‘ç°æŸ¥è¯¢"""
        query_lower = query.lower()
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯çƒ­é—¨ç»„åˆå‘ç°æŸ¥è¯¢
        if any(keyword in query_lower for keyword in ['çƒ­é—¨', 'æµè¡Œ', 'è¶‹åŠ¿']) and any(keyword in query_lower for keyword in ['ç»„åˆ', 'æ­é…', 'é£Ÿæ']):
            # è·å–çƒ­é—¨é£Ÿæç»„åˆ
            if self.recommendation_engine:
                combinations = self.recommendation_engine.discover_trending_combinations()
            else:
                # å¦‚æœæ²¡æœ‰æ¨èå¼•æ“ï¼Œä½¿ç”¨å›¾ç»“æ„ç›´æ¥è®¡ç®—
                combinations = self._discover_trending_combinations_direct()
            
            # è½¬æ¢ä¸ºç»“æœæ ¼å¼
            results = []
            for combination, count in combinations:
                # åˆ›å»ºè™šæ‹ŸèŠ‚ç‚¹æ¥è¡¨ç¤ºç»„åˆ
                from graph_models import GraphNode, NodeType
                combination_node = GraphNode(
                    id=f"combination_{'_'.join(combination)}",
                    node_type=NodeType.INGREDIENT,  # ä½¿ç”¨INGREDIENTç±»å‹
                    name=" + ".join(combination),
                    properties={
                        "type": "ingredient_combination",
                        "ingredients": combination,
                        "cooccurrence_count": count
                    }
                )
                results.append((combination_node, count))
            
            return QueryResult("discovery", results, {
                "discovery_type": "trending_combinations",
                "total_combinations": len(results)
            })
        
        # å…¶ä»–å‘ç°æŸ¥è¯¢ç±»å‹å¯ä»¥åœ¨è¿™é‡Œæ‰©å±•
        else:
            return QueryResult("discovery", [], {"error": "æœªæ”¯æŒçš„å‘ç°æŸ¥è¯¢ç±»å‹"})
    
    def _discover_trending_combinations_direct(self, min_cooccurrence: int = 3) -> List[Tuple[List[str], int]]:
        """ç›´æ¥ä½¿ç”¨å›¾ç»“æ„å‘ç°çƒ­é—¨é£Ÿæç»„åˆ"""
        from collections import defaultdict
        
        # ç»Ÿè®¡æ‰€æœ‰é£Ÿæå¯¹çš„å‡ºç°é¢‘ç‡
        ingredient_pairs = defaultdict(int)
        
        # è·å–æ‰€æœ‰èœå“
        dish_nodes = self.graph.find_nodes_by_type(NodeType.DISH)
        
        for dish in dish_nodes:
            ingredients = self.graph.get_neighbors(dish.id, EdgeType.CONTAINS)
            ingredient_names = [ing.name for ing in ingredients]
            
            # ç”Ÿæˆæ‰€æœ‰å¯èƒ½çš„é£Ÿæå¯¹
            for i in range(len(ingredient_names)):
                for j in range(i + 1, len(ingredient_names)):
                    pair = tuple(sorted([ingredient_names[i], ingredient_names[j]]))
                    ingredient_pairs[pair] += 1
        
        # è¿‡æ»¤å¹¶æ’åº
        trending_combinations = []
        for pair, count in ingredient_pairs.items():
            if count >= min_cooccurrence:
                trending_combinations.append((list(pair), count))
        
        trending_combinations.sort(key=lambda x: x[1], reverse=True)
        return trending_combinations[:20]  # è¿”å›å‰20ä¸ªçƒ­é—¨ç»„åˆ
    
    def generate_llm_enhanced_answer(self, query: str, result: QueryResult) -> str:
        """
        ç”ŸæˆLLMå¢å¼ºçš„å›ç­”
        
        Args:
            query: åŸå§‹æŸ¥è¯¢
            result: æŸ¥è¯¢ç»“æœ
            
        Returns:
            LLMå¢å¼ºçš„å›ç­”
        """
        if not self.llm_integration:
            return self._generate_simple_answer(query, result)
        
         # æ£€æŸ¥æ˜¯å¦æœ‰å›¾è°±ä¿¡æ¯
        has_graph_info = result.results and len(result.results) > 0
    
        if has_graph_info:
            # æœ‰å›¾è°±ä¿¡æ¯æ—¶ï¼Œä½¿ç”¨å›¾è°±ä¿¡æ¯ç”Ÿæˆå›ç­”
            # æ„å»ºå›¾ä¸Šä¸‹æ–‡
            from llm_integration import GraphContext
        
            # ä»ç»“æœä¸­æå–èŠ‚ç‚¹å’Œè¾¹ä¿¡æ¯
            nodes = []
            edges = []
            relationships = []
            
            if result.results:
                for item in result.results:
                    if isinstance(item, tuple) and len(item) >= 1:
                        # å¤„ç† (node, score) æ ¼å¼
                        node = item[0]
                        if hasattr(node, 'id') and hasattr(node, 'name'):
                            nodes.append(node)
                    elif hasattr(item, 'id') and hasattr(item, 'name'):
                        # å¤„ç†å•ä¸ªèŠ‚ç‚¹
                        nodes.append(item)
            
            # æ„å»ºå…³ç³»ä¿¡æ¯
            for node in nodes:
                # è·å–èŠ‚ç‚¹çš„é‚»å±…å…³ç³»
                neighbors = self.graph.get_neighbors(node.id)
                for neighbor in neighbors:
                    # è·å–è¾¹ä¿¡æ¯
                    node_edges = self.graph.get_edges(node.id, neighbor.id)
                    edges.extend(node_edges)
                    
                    # æ„å»ºå…³ç³»æè¿°
                    for edge in node_edges:
                        relationships.append({
                            'source': node.name,
                            'target': neighbor.name,
                            'type': edge.edge_type.value,
                            'weight': edge.weight
                        })
            
            # åˆ›å»ºå›¾ä¸Šä¸‹æ–‡
            graph_context = GraphContext(
                nodes=nodes,
                edges=edges,
                relationships=relationships,
                statistics=result.metadata or {}
            )
        
            # ç”ŸæˆLLMå¢å¼ºå›ç­”
            return self.llm_integration.generate_intelligent_answer(query, graph_context)
        else:
            # æ²¡æœ‰å›¾è°±ä¿¡æ¯æ—¶ï¼Œä½¿ç”¨é€šç”¨çŸ¥è¯†ç”Ÿæˆå›ç­”
            return self.llm_integration.generate_fallback_answer(query)
    
    def _generate_simple_answer(self, query: str, result: QueryResult) -> str:
        """
        ç”Ÿæˆç®€å•å›ç­”ï¼ˆå½“LLMä¸å¯ç”¨æ—¶ï¼‰
        
        Args:
            query: åŸå§‹æŸ¥è¯¢
            result: æŸ¥è¯¢ç»“æœ
            
        Returns:
            ç®€å•å›ç­”
        """
        if not result.results:
            return "æŠ±æ­‰ï¼Œæ²¡æœ‰æ‰¾åˆ°ç›¸å…³ä¿¡æ¯ã€‚"
        
        answer_parts = [f"åŸºäºæ‚¨çš„æŸ¥è¯¢ã€Œ{query}ã€ï¼Œæˆ‘æ‰¾åˆ°äº†ä»¥ä¸‹ä¿¡æ¯ï¼š\n"]
        
        if result.query_type == "pairing":
            answer_parts.append("ğŸ”— é£Ÿææ­é…ä¿¡æ¯ï¼š")
            for i, (ingredient, count) in enumerate(result.results[:5], 1):
                answer_parts.append(f"{i}. {ingredient.name} (å…±åŒå‡ºç° {count} æ¬¡)")
        
        elif result.query_type == "recommendation":
            answer_parts.append("ğŸ’¡ æ¨èç»“æœï¼š")
            for i, (item, score) in enumerate(result.results[:5], 1):
                answer_parts.append(f"{i}. {item.name} (æ¨èåº¦: {score:.2f})")
        
        elif result.query_type == "similarity":
            answer_parts.append("ğŸ” ç›¸ä¼¼èœå“ï¼š")
            for i, (dish, score) in enumerate(result.results[:5], 1):
                answer_parts.append(f"{i}. {dish.name} (ç›¸ä¼¼åº¦: {score:.2f})")
        
        elif result.query_type == "discovery":
            answer_parts.append("ğŸ” å‘ç°ç»“æœï¼š")
            for i, (item, score) in enumerate(result.results[:5], 1):
                if hasattr(item, 'properties') and item.properties.get('type') == 'ingredient_combination':
                    ingredients = item.properties.get('ingredients', [])
                    answer_parts.append(f"{i}. {' + '.join(ingredients)} (å…±åŒå‡ºç° {score} æ¬¡)")
                else:
                    answer_parts.append(f"{i}. {item.name} (ç›¸å…³åº¦: {score})")
        
        else:
            answer_parts.append("ğŸ“‹ æŸ¥è¯¢ç»“æœï¼š")
            for i, item in enumerate(result.results[:5], 1):
                if hasattr(item, 'name'):
                    answer_parts.append(f"{i}. {item.name}")
                else:
                    answer_parts.append(f"{i}. {item}")
        
        return "\n".join(answer_parts)
    
    def _process_analysis_query(self, query: str) -> QueryResult:
        """å¤„ç†åˆ†ææŸ¥è¯¢"""
        # æå–è¦åˆ†æçš„å¯¹è±¡åç§°
        target_name = self._extract_target_from_analysis_query(query)
        
        if not target_name:
            return QueryResult("analysis", [], {"error": "æœªæ‰¾åˆ°åˆ†æå¯¹è±¡"})
        
        # å°è¯•åˆ†æä¸åŒç±»å‹çš„å¯¹è±¡
        analysis_results = []
        
        # 1. å°è¯•ä½œä¸ºé£Ÿæåˆ†æ
        ingredient_nodes = self.query_engine.search_nodes(target_name, NodeType.INGREDIENT)
        if ingredient_nodes:
            analysis = self.analyze_ingredient_network(target_name)
            analysis_results.append({
                "type": "ingredient",
                "name": target_name,
                "analysis": analysis
            })
        
        # 2. å°è¯•ä½œä¸ºèœå“åˆ†æ
        dish_nodes = self.query_engine.search_nodes(target_name, NodeType.DISH)
        if dish_nodes:
            dish_analysis = self._analyze_dish_network(target_name)
            analysis_results.append({
                "type": "dish",
                "name": target_name,
                "analysis": dish_analysis
            })
        
        # 3. å°è¯•ä½œä¸ºçƒ¹é¥ªæ–¹æ³•åˆ†æ
        method_nodes = self.query_engine.search_nodes(target_name, NodeType.COOKING_METHOD)
        if method_nodes:
            method_analysis = self._analyze_cooking_method_network(target_name)
            analysis_results.append({
                "type": "cooking_method",
                "name": target_name,
                "analysis": method_analysis
            })
        
        return QueryResult("analysis", analysis_results, {
            "target_name": target_name,
            "analysis_count": len(analysis_results)
        })
    
    def _process_general_query(self, query: str) -> QueryResult:
        """å¤„ç†ä¸€èˆ¬æŸ¥è¯¢"""
        # å°è¯•æœç´¢æ‰€æœ‰ç±»å‹çš„èŠ‚ç‚¹
        all_results = []
        
        for node_type in NodeType:
            nodes = self.query_engine.search_nodes(query, node_type, limit=5)
            all_results.extend(nodes)
        
        return QueryResult("general", all_results, {
            "query_text": query,
            "total_results": len(all_results)
        })
    
    def _extract_target_from_analysis_query(self, query: str) -> Optional[str]:
        """ä»åˆ†ææŸ¥è¯¢ä¸­æå–ç›®æ ‡å¯¹è±¡åç§°"""
        # ç§»é™¤åˆ†æå…³é”®è¯
        analysis_keywords = ['åˆ†æ', 'äº†è§£', 'ä»‹ç»', 'è¯´æ˜', 'ä¸€ä¸‹', 'çš„']
        
        target = query
        for keyword in analysis_keywords:
            target = target.replace(keyword, '').strip()
        
        # ç§»é™¤å¸¸è§çš„åœç”¨è¯
        stop_words = ['ä¸€ä¸‹', 'çš„', 'è¿™ä¸ª', 'é‚£ä¸ª', 'ä»€ä¹ˆ', 'å¦‚ä½•', 'æ€æ ·']
        for word in stop_words:
            target = target.replace(word, '').strip()
        
        return target if target else None
    
    def _analyze_dish_network(self, dish_name: str) -> Dict[str, Any]:
        """åˆ†æèœå“ç½‘ç»œ"""
        # æŸ¥æ‰¾èœå“èŠ‚ç‚¹
        dish_nodes = self.query_engine.search_nodes(dish_name, NodeType.DISH)
        if not dish_nodes:
            return {"error": "æœªæ‰¾åˆ°èœå“"}
        
        analysis = {
            "dish": dish_name,
            "total_ingredients": 0,
            "cooking_methods": [],
            "categories": [],
            "similar_dishes": []
        }
        
        for dish in dish_nodes:
            # è·å–èœå“çš„é£Ÿæ
            ingredients = self.graph.get_neighbors(dish.id, EdgeType.CONTAINS)
            analysis["total_ingredients"] += len(ingredients)
            
            # è·å–çƒ¹é¥ªæ–¹æ³•
            methods = self.graph.get_neighbors(dish.id, EdgeType.USES_METHOD)
            analysis["cooking_methods"].extend([method.name for method in methods])
            
            # è·å–åˆ†ç±»
            categories = self.graph.get_neighbors(dish.id, EdgeType.BELONGS_TO)
            analysis["categories"].extend([cat.name for cat in categories])
            
            # è·å–ç›¸ä¼¼èœå“
            similar_edges = self.graph.get_edges(dish.id, edge_type=EdgeType.SIMILAR_TO)
            for edge in similar_edges:
                similar_dish = self.graph.get_node(edge.target_id)
                if similar_dish:
                    analysis["similar_dishes"].append((similar_dish.name, edge.weight))
        
        # å»é‡å¹¶æ’åº
        analysis["cooking_methods"] = list(set(analysis["cooking_methods"]))
        analysis["categories"] = list(set(analysis["categories"]))
        analysis["similar_dishes"].sort(key=lambda x: x[1], reverse=True)
        
        return analysis
    
    def _analyze_cooking_method_network(self, method_name: str) -> Dict[str, Any]:
        """åˆ†æçƒ¹é¥ªæ–¹æ³•ç½‘ç»œ"""
        # æŸ¥æ‰¾çƒ¹é¥ªæ–¹æ³•èŠ‚ç‚¹
        method_nodes = self.query_engine.search_nodes(method_name, NodeType.COOKING_METHOD)
        if not method_nodes:
            return {"error": "æœªæ‰¾åˆ°çƒ¹é¥ªæ–¹æ³•"}
        
        analysis = {
            "method": method_name,
            "total_dishes": 0,
            "common_ingredients": [],
            "categories": []
        }
        
        for method in method_nodes:
            # è·å–ä½¿ç”¨è¯¥æ–¹æ³•çš„èœå“
            dishes = self.graph.get_neighbors(method.id, EdgeType.USES_METHOD)
            analysis["total_dishes"] += len(dishes)
            
            # ç»Ÿè®¡å¸¸ç”¨é£Ÿæ
            ingredient_counts = Counter()
            for dish in dishes:
                ingredients = self.graph.get_neighbors(dish.id, EdgeType.CONTAINS)
                for ingredient in ingredients:
                    ingredient_counts[ingredient.name] += 1
            
            # è·å–å‰10ä¸ªå¸¸ç”¨é£Ÿæ
            analysis["common_ingredients"] = ingredient_counts.most_common(10)
            
            # è·å–åˆ†ç±»
            for dish in dishes:
                categories = self.graph.get_neighbors(dish.id, EdgeType.BELONGS_TO)
                analysis["categories"].extend([cat.name for cat in categories])
        
        # å»é‡
        analysis["categories"] = list(set(analysis["categories"]))
        
        return analysis
    
    def _extract_ingredients_from_query(self, query: str) -> List[str]:
        """ä»æŸ¥è¯¢ä¸­æå–é£Ÿæåç§°"""
        # ç®€å•çš„å…³é”®è¯æå–
        ingredients = []
        
        # å¸¸è§çš„é£Ÿæå…³é”®è¯
        ingredient_keywords = [
            'é¸¡', 'é¸­', 'çŒª', 'ç‰›', 'ç¾Š', 'é±¼', 'è™¾', 'èŸ¹',
            'ç™½èœ', 'èåœ', 'åœŸè±†', 'è¥¿çº¢æŸ¿', 'é»„ç“œ', 'èŒ„å­', 'è±†è§’', 'é’æ¤’', 'çº¢æ¤’',
            'æ´‹è‘±', 'è’œ', 'å§œ', 'è‘±', 'éŸ­èœ', 'è èœ', 'èŠ¹èœ', 'èŠ±èœ', 'è¥¿å…°èŠ±',
            'èƒ¡èåœ', 'å†¬ç“œ', 'å—ç“œ', 'ä¸ç“œ', 'è‹¦ç“œ', 'è±†èŠ½', 'è˜‘è‡', 'é¦™è‡',
            'é‡‘é’ˆè‡', 'æœ¨è€³', 'é“¶è€³', 'é¸¡è›‹', 'é¸­è›‹', 'è±†è…', 'è±†å¹²', 'è±†çš®',
            'ç±³', 'é¢', 'é¢æ¡', 'æŒ‚é¢', 'æ„é¢', 'é¥ºå­', 'åŒ…å­', 'é¦’å¤´', 'é¥¼', 'é¥­', 'ç²¥'
        ]
        
        for keyword in ingredient_keywords:
            if keyword in query:
                ingredients.append(keyword)
        
        return ingredients
    
    def _extract_dishes_from_query(self, query: str) -> List[str]:
        """ä»æŸ¥è¯¢ä¸­æå–èœå“åç§°"""
        dishes = []
        
        # å¸¸è§çš„èœå“å…³é”®è¯
        dish_keywords = [
            'ç‚’', 'ç…®', 'è’¸', 'ç‚¸', 'çƒ¤', 'ç‚–', 'ç„–', 'ç…', 'æ‹Œ', 'å‡‰æ‹Œ',
            'çº¢çƒ§', 'æ¸…ç‚’', 'çˆ†ç‚’', 'å¹²ç…¸', 'æ°´ç…®', 'æ¸…è’¸', 'ç³–é†‹',
            'éº»è¾£', 'é¦™è¾£', 'é…¸è¾£', 'è’œè“‰', 'èšæ²¹', 'ç™½ç¼', 'ä¸Šæ±¤'
        ]
        
        # æ–¹æ³•1: æŸ¥æ‰¾åŒ…å«çƒ¹é¥ªæ–¹æ³•çš„è¯æ±‡
        for keyword in dish_keywords:
            if keyword in query:
                # å°è¯•æå–å®Œæ•´çš„èœå“åç§°
                pattern = rf'(\w*{keyword}\w*)'
                matches = re.findall(pattern, query)
                dishes.extend(matches)
        
        # æ–¹æ³•2: å¦‚æœæŸ¥è¯¢ä¸­åŒ…å«"å’Œ"æˆ–"ä¸"ï¼Œå°è¯•æå–"å’Œ"å‰é¢çš„èœå“åç§°
        if 'å’Œ' in query or 'ä¸' in query:
            # æå–"å’Œ"å‰é¢çš„éƒ¨åˆ†ä½œä¸ºèœå“åç§°
            if 'å’Œ' in query:
                dish_part = query.split('å’Œ')[0].strip()
            else:
                dish_part = query.split('ä¸')[0].strip()
            
            # ç§»é™¤å¸¸è§çš„åœç”¨è¯
            stop_words = ['çš„', 'èœ', 'èœå“', 'é£Ÿç‰©']
            for word in stop_words:
                dish_part = dish_part.replace(word, '').strip()
            
            if dish_part and len(dish_part) > 1:
                dishes.append(dish_part)
        
        # æ–¹æ³•2.5: å¦‚æœæŸ¥è¯¢ä¸­åŒ…å«"å’Œ...ç›¸ä¼¼çš„"ï¼Œå°è¯•æå–"å’Œ"å’Œ"ç›¸ä¼¼"ä¹‹é—´çš„èœå“åç§°
        if 'å’Œ' in query and 'ç›¸ä¼¼' in query:
            # æ‰¾åˆ°"å’Œ"çš„ä½ç½®
            he_pos = query.find('å’Œ')
            # æ‰¾åˆ°"ç›¸ä¼¼"çš„ä½ç½®
            similar_pos = query.find('ç›¸ä¼¼')
            
            if he_pos < similar_pos:
                # æå–"å’Œ"å’Œ"ç›¸ä¼¼"ä¹‹é—´çš„éƒ¨åˆ†
                dish_part = query[he_pos+1:similar_pos].strip()
                
                # ç§»é™¤å¸¸è§çš„åœç”¨è¯
                stop_words = ['çš„', 'èœ', 'èœå“', 'é£Ÿç‰©']
                for word in stop_words:
                    dish_part = dish_part.replace(word, '').strip()
                
                if dish_part and len(dish_part) > 1:
                    dishes.append(dish_part)
        
        # æ–¹æ³•3: å¦‚æœæŸ¥è¯¢ä¸­åŒ…å«"ç±»ä¼¼"æˆ–"åƒ"ï¼Œå°è¯•æå–åé¢çš„èœå“åç§°
        if 'ç±»ä¼¼' in query:
            parts = query.split('ç±»ä¼¼')
            if len(parts) > 1:
                dish_part = parts[1].strip()
                # ç§»é™¤å¸¸è§çš„åœç”¨è¯
                stop_words = ['çš„', 'èœ', 'èœå“', 'é£Ÿç‰©']
                for word in stop_words:
                    dish_part = dish_part.replace(word, '').strip()
                if dish_part and len(dish_part) > 1:
                    dishes.append(dish_part)
        
        if 'åƒ' in query:
            parts = query.split('åƒ')
            if len(parts) > 1:
                dish_part = parts[1].strip()
                # ç§»é™¤å¸¸è§çš„åœç”¨è¯
                stop_words = ['çš„', 'èœ', 'èœå“', 'é£Ÿç‰©']
                for word in stop_words:
                    dish_part = dish_part.replace(word, '').strip()
                if dish_part and len(dish_part) > 1:
                    dishes.append(dish_part)
        
        return dishes
    
    def _extract_cooking_methods_from_query(self, query: str) -> List[str]:
        """ä»æŸ¥è¯¢ä¸­æå–çƒ¹é¥ªæ–¹æ³•"""
        methods = []
        
        cooking_methods = [
            'ç‚’', 'ç…®', 'è’¸', 'ç‚¸', 'çƒ¤', 'ç‚–', 'ç„–', 'ç…', 'æ‹Œ', 'å‡‰æ‹Œ',
            'çº¢çƒ§', 'æ¸…ç‚’', 'çˆ†ç‚’', 'å¹²ç…¸', 'æ°´ç…®', 'æ¸…è’¸', 'ç³–é†‹',
            'éº»è¾£', 'é¦™è¾£', 'é…¸è¾£', 'è’œè“‰', 'èšæ²¹', 'ç™½ç¼', 'ä¸Šæ±¤', 'å‹¾èŠ¡'
        ]
        
        for method in cooking_methods:
            if method in query:
                methods.append(method)
        
        return methods
    
    def analyze_ingredient_network(self, ingredient_name: str) -> Dict[str, Any]:
        """åˆ†æé£Ÿæç½‘ç»œ"""
        # æŸ¥æ‰¾é£ŸæèŠ‚ç‚¹
        ingredient_nodes = self.query_engine.search_nodes(ingredient_name, NodeType.INGREDIENT)
        if not ingredient_nodes:
            return {"error": "æœªæ‰¾åˆ°é£Ÿæ"}
        
        analysis = {
            "ingredient": ingredient_name,
            "total_dishes": 0,
            "common_pairings": [],
            "cooking_methods": [],
            "categories": [],
            "substitution_suggestions": []
        }
        
        for ingredient in ingredient_nodes:
            # ç»Ÿè®¡åŒ…å«è¯¥é£Ÿæçš„èœå“æ•°é‡
            dishes = self.graph.get_neighbors(ingredient.id, EdgeType.CONTAINS)
            analysis["total_dishes"] += len(dishes)
            
            # è·å–æ­é…é£Ÿæ
            pairs = self.query_engine.find_ingredient_pairs(ingredient.name)
            analysis["common_pairings"].extend(pairs[:10])  # å‰10ä¸ª
            
            # è·å–çƒ¹é¥ªæ–¹æ³•
            methods = self.query_engine.find_cooking_methods_for_ingredient(ingredient.name)
            analysis["cooking_methods"].extend(methods[:10])  # å‰10ä¸ª
            
            # è·å–åˆ†ç±»ä¿¡æ¯
            if ingredient.properties.get('category'):
                analysis["categories"].append(ingredient.properties['category'])
            
            # è·å–æ›¿ä»£å»ºè®®
            substitutions = self.query_engine.get_ingredient_substitution_suggestions(ingredient.name)
            analysis["substitution_suggestions"].extend(substitutions[:5])  # å‰5ä¸ª
        
        # å»é‡å¹¶æ’åº
        analysis["common_pairings"] = list(set(analysis["common_pairings"]))
        analysis["cooking_methods"] = list(set(analysis["cooking_methods"]))
        analysis["categories"] = list(set(analysis["categories"]))
        analysis["substitution_suggestions"] = list(set(analysis["substitution_suggestions"]))
        
        return analysis
    
    def find_recipe_paths(self, start_ingredient: str, end_ingredient: str) -> List[List[GraphNode]]:
        """æŸ¥æ‰¾é£Ÿè°±è·¯å¾„"""
        return self.query_engine.find_path_between_ingredients(start_ingredient, end_ingredient)
    
    def get_ingredient_compatibility_matrix(self, ingredients: List[str]) -> Dict[str, Dict[str, float]]:
        """è·å–é£Ÿæå…¼å®¹æ€§çŸ©é˜µ"""
        matrix = {}
        
        for i, ingredient1 in enumerate(ingredients):
            matrix[ingredient1] = {}
            pairs1 = self.query_engine.find_ingredient_pairs(ingredient1)
            pair_dict1 = {pair[0].name: pair[1] for pair in pairs1}
            
            for j, ingredient2 in enumerate(ingredients):
                if i == j:
                    matrix[ingredient1][ingredient2] = 1.0
                else:
                    # è®¡ç®—å…¼å®¹æ€§åˆ†æ•°
                    compatibility = pair_dict1.get(ingredient2, 0) / 10.0  # å½’ä¸€åŒ–
                    matrix[ingredient1][ingredient2] = min(compatibility, 1.0)
        
        return matrix
